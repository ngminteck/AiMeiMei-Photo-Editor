{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bfd0ee9-9cf2-4c2b-ba85-c161b595375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 16 CPU cores. Configured PyTorch to use 16 threads.\n",
      "Added positive point: (540.0, 538.0)\n",
      "Merged prompt-based selection into union mask.\n",
      "Added positive point: (525.0, 470.0)\n",
      "Merged prompt-based selection into union mask.\n",
      "Mode set to: transform\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PyQt6.QtWidgets import (\n",
    "    QApplication,\n",
    "    QGraphicsView,\n",
    "    QGraphicsScene,\n",
    "    QGraphicsPixmapItem,\n",
    "    QVBoxLayout,\n",
    "    QWidget,\n",
    "    QPushButton,\n",
    "    QButtonGroup\n",
    ")\n",
    "from PyQt6.QtGui import (\n",
    "    QPixmap,\n",
    "    QPen,\n",
    "    QColor,\n",
    "    QPainter,\n",
    "    QImage,\n",
    "    QPainterPath\n",
    ")\n",
    "from PyQt6.QtCore import Qt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import multiprocessing \n",
    "from segment_anything import SamPredictor, SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Initialize SAM model and predictors with evaluation mode.\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    SAM_CHECKPOINT = \"models/sam_vit_h_4b8939.pth\"  \n",
    "    MODEL_TYPE = \"vit_h\" \n",
    "else:\n",
    "    SAM_CHECKPOINT = \"models/sam_vit_b_01ec64.pth\"\n",
    "    MODEL_TYPE = \"vit_b\"\n",
    "    cpu_core_count = multiprocessing.cpu_count()\n",
    "    torch.set_num_threads(cpu_core_count)\n",
    "    print(f\"Detected {cpu_core_count} CPU cores. Configured PyTorch to use {cpu_core_count} threads.\")\n",
    "\n",
    "sam_model = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT)\n",
    "sam_model.to(DEVICE)\n",
    "sam_model.eval()  # Ensure model is in evaluation mode.\n",
    "\n",
    "predictor = SamPredictor(sam_model)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Adjust auto mask generator parameters.\n",
    "# Lowering points_per_side speeds up the process.\n",
    "# ---------------------------------------------------------------------------\n",
    "auto_mask_generator = SamAutomaticMaskGenerator(\n",
    "    sam_model,\n",
    "    points_per_side=32,          # Reduced density for faster computation.\n",
    "    pred_iou_thresh=0.80,        \n",
    "    stability_score_thresh=0.90, \n",
    "    min_mask_region_area=500     \n",
    ")\n",
    "\n",
    "class CustomGraphicsView(QGraphicsView):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scene = QGraphicsScene()\n",
    "        self.setScene(self.scene)\n",
    "        self.main_pixmap_item = None\n",
    "        self.original_pixmap = None\n",
    "        self.background_pixmap = None\n",
    "        self.selected_pixmap_item = None\n",
    "        self.selection_feedback_item = None\n",
    "        self.dragging = False\n",
    "\n",
    "        # Modes: \"selection\" (prompt-based), \"auto\" (auto-based), \"transform\" (move/scale)\n",
    "        self.mode = \"selection\"\n",
    "\n",
    "        # For prompt-based mode: store positive/negative points\n",
    "        self.positive_points = []\n",
    "        self.negative_points = []\n",
    "\n",
    "        # Union mask for merged selections.\n",
    "        self.auto_selection_mask = None  # uint8 array: 0 or 255 values.\n",
    "        self.image_shape = None\n",
    "\n",
    "        # Cache for full-resolution image.\n",
    "        self.cv_image = None\n",
    "        # For speeding up auto mask generation, we downscale the image.\n",
    "        self.downscale_factor = 0.5  # Adjust factor as needed.\n",
    "        self.cv_image_small = None  # Downscaled version.\n",
    "        self.image_rgb_small = None\n",
    "\n",
    "        # Cache auto masks computed on the downscaled image.\n",
    "        self.cached_masks = None\n",
    "\n",
    "        # Toggle for morphological post-processing.\n",
    "        self.use_morphology = True\n",
    "\n",
    "        self.setRenderHint(QPainter.RenderHint.Antialiasing)\n",
    "        self.setRenderHint(QPainter.RenderHint.SmoothPixmapTransform)\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        self.image_path = image_path\n",
    "        self.original_pixmap = QPixmap(image_path)\n",
    "        self.background_pixmap = QPixmap(image_path)\n",
    "        if self.original_pixmap.isNull():\n",
    "            print(f\"Error: Could not load image from {image_path}\")\n",
    "            return\n",
    "\n",
    "        # Load full-resolution image with cv2.\n",
    "        self.cv_image = cv2.imread(image_path)\n",
    "        if self.cv_image is not None:\n",
    "            self.image_shape = (self.cv_image.shape[0], self.cv_image.shape[1])\n",
    "            self.auto_selection_mask = np.zeros(self.image_shape, dtype=np.uint8)\n",
    "\n",
    "            # Create a downscaled version to speed up auto mask generation.\n",
    "            self.cv_image_small = cv2.resize(self.cv_image, (0, 0), fx=self.downscale_factor, fy=self.downscale_factor)\n",
    "            self.image_rgb_small = cv2.cvtColor(self.cv_image_small, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Generate and cache auto masks on the downscaled image.\n",
    "            with torch.no_grad():\n",
    "                self.cached_masks = auto_mask_generator.generate(self.image_rgb_small)\n",
    "        else:\n",
    "            print(\"Error loading image with cv2\")\n",
    "            return\n",
    "\n",
    "        self.main_pixmap_item = QGraphicsPixmapItem(self.original_pixmap)\n",
    "        self.scene.addItem(self.main_pixmap_item)\n",
    "        self.setSceneRect(self.main_pixmap_item.boundingRect())\n",
    "\n",
    "    def set_mode(self, mode):\n",
    "        self.mode = mode\n",
    "        print(f\"Mode set to: {mode}\")\n",
    "        if mode != \"selection\":\n",
    "            self.positive_points = []\n",
    "            self.negative_points = []\n",
    "\n",
    "    # --- Prompt-based selection ---\n",
    "    def ai_salient_object_selection(self):\n",
    "        if self.cv_image is None:\n",
    "            print(\"No image loaded\")\n",
    "            return\n",
    "        if not self.positive_points and not self.negative_points:\n",
    "            print(\"No selection points provided\")\n",
    "            return\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Use full-resolution RGB image for prompt-based selection.\n",
    "            image_rgb = cv2.cvtColor(self.cv_image, cv2.COLOR_BGR2RGB)\n",
    "            predictor.set_image(image_rgb)\n",
    "\n",
    "            points = []\n",
    "            labels = []\n",
    "            if self.positive_points:\n",
    "                points.extend(self.positive_points)\n",
    "                labels.extend([1] * len(self.positive_points))\n",
    "            if self.negative_points:\n",
    "                points.extend(self.negative_points)\n",
    "                labels.extend([0] * len(self.negative_points))\n",
    "            points_array = np.array(points)\n",
    "            labels_array = np.array(labels)\n",
    "\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=points_array,\n",
    "                point_labels=labels_array,\n",
    "                multimask_output=False\n",
    "            )\n",
    "\n",
    "        mask = masks[0]\n",
    "        mask_uint8 = (mask.astype(np.uint8)) * 255\n",
    "        if self.use_morphology:\n",
    "            kernel = np.ones((5, 5), np.uint8)\n",
    "            mask_uint8 = cv2.morphologyEx(mask_uint8, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Merge prompt-based mask into the union mask.\n",
    "        self.auto_selection_mask = cv2.bitwise_or(self.auto_selection_mask, mask_uint8)\n",
    "        print(\"Merged prompt-based selection into union mask.\")\n",
    "        self.positive_points = []\n",
    "        self.negative_points = []\n",
    "        self.update_auto_selection_display()\n",
    "\n",
    "    # --- Auto mode: update selection based on auto mask generator ---\n",
    "    def auto_salient_object_update(self, click_point, action=\"add\"):\n",
    "        if self.cv_image is None:\n",
    "            print(\"No image loaded\")\n",
    "            return\n",
    "        if self.cached_masks is None:\n",
    "            print(\"No masks generated\")\n",
    "            return\n",
    "\n",
    "        # Convert click coordinates from full-resolution to downscaled image.\n",
    "        x = int(click_point.x())\n",
    "        y = int(click_point.y())\n",
    "        x_small = int(x * self.downscale_factor)\n",
    "        y_small = int(y * self.downscale_factor)\n",
    "\n",
    "        selected_mask = None\n",
    "        best_area = 0\n",
    "\n",
    "        # Iterate over cached masks (from downscaled image).\n",
    "        for m in self.cached_masks:\n",
    "            seg = m[\"segmentation\"]\n",
    "            # Check the downscaled coordinates.\n",
    "            if seg[y_small, x_small]:\n",
    "                area = m.get(\"area\", np.sum(seg))\n",
    "                if area > best_area:\n",
    "                    best_area = area\n",
    "                    selected_mask = seg\n",
    "\n",
    "        if selected_mask is None:\n",
    "            selected_mask = max(self.cached_masks, key=lambda m: m.get(\"area\", np.sum(m[\"segmentation\"])))[\"segmentation\"]\n",
    "\n",
    "        # Upsample the selected mask back to full resolution.\n",
    "        up_mask = cv2.resize(selected_mask.astype(np.uint8), \n",
    "                             (self.image_shape[1], self.image_shape[0]), \n",
    "                             interpolation=cv2.INTER_NEAREST)\n",
    "        new_mask = up_mask * 255\n",
    "\n",
    "        if self.use_morphology:\n",
    "            kernel = np.ones((5, 5), np.uint8)\n",
    "            new_mask = cv2.morphologyEx(new_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        if action == \"add\":\n",
    "            self.auto_selection_mask = cv2.bitwise_or(self.auto_selection_mask, new_mask)\n",
    "            print(\"Added object to selection (auto).\")\n",
    "        elif action == \"remove\":\n",
    "            inv = cv2.bitwise_not(new_mask)\n",
    "            self.auto_selection_mask = cv2.bitwise_and(self.auto_selection_mask, inv)\n",
    "            print(\"Removed object from selection (auto).\")\n",
    "        else:\n",
    "            print(\"Unknown action\")\n",
    "        self.update_auto_selection_display()\n",
    "\n",
    "    # --- Update display based on the union mask ---\n",
    "    def update_auto_selection_display(self):\n",
    "        if self.cv_image is None or self.auto_selection_mask is None:\n",
    "            return\n",
    "\n",
    "        # Copy full-resolution image.\n",
    "        img = self.cv_image.copy()\n",
    "        mask_uint8 = self.auto_selection_mask.copy()\n",
    "\n",
    "        # Draw an outline around the union mask.\n",
    "        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        path = QPainterPath()\n",
    "        for cnt in contours:\n",
    "            if len(cnt) > 0:\n",
    "                cnt = cnt.squeeze()\n",
    "                if cnt.ndim < 2:\n",
    "                    continue\n",
    "                start = cnt[0]\n",
    "                path.moveTo(start[0], start[1])\n",
    "                for pt in cnt[1:]:\n",
    "                    path.lineTo(pt[0], pt[1])\n",
    "                path.closeSubpath()\n",
    "        if self.selection_feedback_item:\n",
    "            self.scene.removeItem(self.selection_feedback_item)\n",
    "        self.selection_feedback_item = self.scene.addPath(path, QPen(QColor(\"black\"), 2))\n",
    "\n",
    "        # Create an overlay pixmap from the union mask.\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_rgba = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2RGBA)\n",
    "        img_rgba[:, :, 3] = mask_uint8\n",
    "        result = cv2.bitwise_and(img_rgba, img_rgba, mask=mask_uint8)\n",
    "\n",
    "        h, w, ch = result.shape\n",
    "        bytes_per_line = ch * w\n",
    "        q_img = QImage(result.data, w, h, bytes_per_line, QImage.Format.Format_RGBA8888)\n",
    "        selected_pixmap = QPixmap.fromImage(q_img)\n",
    "\n",
    "        if self.selected_pixmap_item:\n",
    "            self.scene.removeItem(self.selected_pixmap_item)\n",
    "        self.selected_pixmap_item = QGraphicsPixmapItem(selected_pixmap)\n",
    "        self.scene.addItem(self.selected_pixmap_item)\n",
    "\n",
    "        # Update main image: set transparency where selection exists.\n",
    "        img_rgba[:, :, 3] = cv2.bitwise_not(mask_uint8)\n",
    "        q_img_main = QImage(img_rgba.data, w, h, bytes_per_line, QImage.Format.Format_RGBA8888)\n",
    "        self.original_pixmap = QPixmap.fromImage(q_img_main)\n",
    "        self.main_pixmap_item.setPixmap(self.original_pixmap)\n",
    "\n",
    "    # --- Merge the transformed selection onto the main image ---\n",
    "    def apply_merge(self):\n",
    "        if not self.main_pixmap_item:\n",
    "            print(\"No current image available.\")\n",
    "            return\n",
    "        if not self.selected_pixmap_item:\n",
    "            print(\"No selected object to merge.\")\n",
    "            return\n",
    "\n",
    "        composite_image = self.main_pixmap_item.pixmap().toImage()\n",
    "        painter = QPainter(composite_image)\n",
    "        selected_pixmap = self.selected_pixmap_item.pixmap()\n",
    "        pos = self.selected_pixmap_item.pos()\n",
    "        painter.drawPixmap(int(pos.x()), int(pos.y()), selected_pixmap)\n",
    "        painter.end()\n",
    "\n",
    "        merged_pixmap = QPixmap.fromImage(composite_image)\n",
    "        self.main_pixmap_item.setPixmap(merged_pixmap)\n",
    "        self.background_pixmap = merged_pixmap\n",
    "\n",
    "        if self.selected_pixmap_item:\n",
    "            self.scene.removeItem(self.selected_pixmap_item)\n",
    "            self.selected_pixmap_item = None\n",
    "        if self.selection_feedback_item:\n",
    "            self.scene.removeItem(self.selection_feedback_item)\n",
    "            self.selection_feedback_item = None\n",
    "\n",
    "        # Reset the union mask and cached masks (since the base image has changed).\n",
    "        self.auto_selection_mask = np.zeros(self.image_shape, dtype=np.uint8)\n",
    "        self.cached_masks = None\n",
    "        print(\"Merge applied: selection merged into current image.\")\n",
    "\n",
    "    # --- Event Handling ---\n",
    "    def mousePressEvent(self, event):\n",
    "        pos = self.mapToScene(event.pos())\n",
    "        if self.mode == \"selection\":\n",
    "            if event.button() == Qt.MouseButton.LeftButton:\n",
    "                self.positive_points.append([pos.x(), pos.y()])\n",
    "                print(f\"Added positive point: ({pos.x()}, {pos.y()})\")\n",
    "            elif event.button() == Qt.MouseButton.RightButton:\n",
    "                self.negative_points.append([pos.x(), pos.y()])\n",
    "                print(f\"Added negative point: ({pos.x()}, {pos.y()})\")\n",
    "            self.ai_salient_object_selection()\n",
    "        elif self.mode == \"auto\":\n",
    "            if event.button() == Qt.MouseButton.LeftButton:\n",
    "                self.auto_salient_object_update(pos, action=\"add\")\n",
    "            elif event.button() == Qt.MouseButton.RightButton:\n",
    "                self.auto_salient_object_update(pos, action=\"remove\")\n",
    "        elif self.mode == \"transform\" and self.selected_pixmap_item:\n",
    "            self.dragging = True\n",
    "            self.drag_start = pos\n",
    "        super().mousePressEvent(event)\n",
    "\n",
    "    def mouseMoveEvent(self, event):\n",
    "        pos = self.mapToScene(event.pos())\n",
    "        if self.dragging and self.selected_pixmap_item:\n",
    "            delta = pos - self.drag_start\n",
    "            self.selected_pixmap_item.moveBy(delta.x(), delta.y())\n",
    "            self.drag_start = pos\n",
    "        super().mouseMoveEvent(event)\n",
    "\n",
    "    def mouseReleaseEvent(self, event):\n",
    "        if event.button() == Qt.MouseButton.LeftButton:\n",
    "            self.dragging = False\n",
    "        super().mouseReleaseEvent(event)\n",
    "\n",
    "    def wheelEvent(self, event):\n",
    "        if self.mode == \"transform\" and self.selected_pixmap_item:\n",
    "            scale_factor = 1.1 if event.angleDelta().y() > 0 else 0.9\n",
    "            self.selected_pixmap_item.setScale(self.selected_pixmap_item.scale() * scale_factor)\n",
    "        super().wheelEvent(event)\n",
    "\n",
    "class MainWindow(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.init_ui()\n",
    "\n",
    "    def init_ui(self):\n",
    "        layout = QVBoxLayout()\n",
    "        self.view = CustomGraphicsView()\n",
    "\n",
    "        self.prompt_selection_button = QPushButton(\"Prompt Selection Mode\")\n",
    "        self.prompt_selection_button.setCheckable(True)\n",
    "        self.auto_selection_button = QPushButton(\"Auto Selection Mode\")\n",
    "        self.auto_selection_button.setCheckable(True)\n",
    "        self.transform_button = QPushButton(\"Transform Mode\")\n",
    "        self.transform_button.setCheckable(True)\n",
    "\n",
    "        self.prompt_selection_button.setChecked(True)\n",
    "        self.auto_selection_button.setChecked(False)\n",
    "        self.transform_button.setChecked(False)\n",
    "\n",
    "        button_group = QButtonGroup(self)\n",
    "        button_group.setExclusive(True)\n",
    "        button_group.addButton(self.prompt_selection_button)\n",
    "        button_group.addButton(self.auto_selection_button)\n",
    "        button_group.addButton(self.transform_button)\n",
    "\n",
    "        self.prompt_selection_button.clicked.connect(lambda: self.view.set_mode(\"selection\"))\n",
    "        self.auto_selection_button.clicked.connect(lambda: self.view.set_mode(\"auto\"))\n",
    "        self.transform_button.clicked.connect(lambda: self.view.set_mode(\"transform\"))\n",
    "\n",
    "        self.apply_merge_button = QPushButton(\"Apply Merge\")\n",
    "        self.apply_merge_button.clicked.connect(lambda: self.view.apply_merge())\n",
    "\n",
    "        layout.addWidget(self.view)\n",
    "        layout.addWidget(self.prompt_selection_button)\n",
    "        layout.addWidget(self.auto_selection_button)\n",
    "        layout.addWidget(self.transform_button)\n",
    "        layout.addWidget(self.apply_merge_button)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle(\"SAM: Merged Selection, Transformation & Apply Tool\")\n",
    "        self.resize(800, 600)\n",
    "        self.view.load_image(\"images/test/2_people_together.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = MainWindow()\n",
    "    window.show()\n",
    "    sys.exit(app.exec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a41b98-56db-465f-8cdf-abc44b4ffa01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
